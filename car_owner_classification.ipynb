{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_owner_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMr/GmdfkzZYT8Gx/q2Z1It",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/nn-practice/blob/main/car_owner_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1sAue48tVB"
      },
      "source": [
        "# **Classifying number of car owners with Classification Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhUVXHd-8-Md"
      },
      "source": [
        "## **1) Importing libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIjXt0L6ogt"
      },
      "source": [
        "# Importing required libraries\n",
        "# Data Handling/ Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Time \n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnfKfFB-G8W"
      },
      "source": [
        "## **2) Data Preprocessing**\n",
        "---\n",
        "**Steps:**\n",
        "\n",
        "1) Columns to encode: Fuel_Type, Seller_Type, Transmission\n",
        "\n",
        "2) Feature Extraction: Extract Age of the vehicle from the Year column\n",
        "\n",
        "3) Columns to delete: Car_Name, Year.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_haD_owD9-W-",
        "outputId": "b39ef6e1-332d-442f-9552-ed9caaf6b807"
      },
      "source": [
        "# Importing dataset\n",
        "dataset = pd.read_csv('car_data.csv')\n",
        "\n",
        "# Calculating age in years of each vehicle\n",
        "dataset['Age'] = dataset['Year'].apply(lambda x: dt.today().year - x)\n",
        "\n",
        "# Deleting car name & year columns\n",
        "dataset.drop(columns = ['Car_Name', 'Year'], inplace = True)\n",
        "\n",
        "# Deleting the row where owner = 3 as only 1 example exists in the dataset\n",
        "dataset = dataset[dataset['Owner'] != 3]\n",
        "print(len(dataset))\n",
        "\n",
        "# Splitting into feature & target matrices\n",
        "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5, 7]].values\n",
        "y = dataset.iloc[:, -2].values.reshape(-1, 1)\n",
        "\n",
        "# Splitting into train & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240, 7), (240, 1), (60, 7), (60, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJto-i-6MIQK",
        "outputId": "7c9bf98f-9de6-4f12-c017-181a3529a5d6"
      },
      "source": [
        "X_train[98]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.1, 4.43, 11849, 'Petrol', 'Dealer', 'Manual', 5], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZ0ZZkaGvyG",
        "outputId": "e1356b03-4caf-4c73-9459-29f4fb792f6e"
      },
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer \n",
        "\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train[:, 3] = enc.fit_transform(X_train[:, 3])\n",
        "X_test[:, 3] = enc.transform(X_test[:, 3])\n",
        "\n",
        "X_train[:, 4] = enc.fit_transform(X_train[:, 4])\n",
        "X_test[:, 4] = enc.transform(X_test[:, 4])\n",
        "\n",
        "X_train[:, 5] = enc.fit_transform(X_train[:, 5])\n",
        "X_test[:, 5] = enc.transform(X_test[:, 5])\n",
        "\n",
        "# OHE the Fuel_Type column\n",
        "ohe = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder = 'passthrough') \n",
        "\n",
        "X_train = ohe.fit_transform(X_train)\n",
        "X_test = ohe.transform(X_test)\n",
        "\n",
        "\n",
        "# Also label encoding the output classes from [0, 1, 3] to [0, 1, 2]\n",
        "y_train[:, 0] = enc.fit_transform(y_train[:, 0])\n",
        "y_test[:, 0] = enc.transform(y_test[:, 0])\n",
        "\n",
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "len(X_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4ohkbzH03v"
      },
      "source": [
        "## **3) PyTorch Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aNk4ro7H0nf",
        "outputId": "831531fb-689f-4bb5-e732-13bb92876ee9"
      },
      "source": [
        "# Converting numpy arrays to torch tensors of dtype float32\n",
        "%time\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32))\n",
        "test_data = TensorDataset(torch.tensor(X_test, dtype = torch.float32), torch.tensor(y_test, dtype = torch.float32))\n",
        "\n",
        "# Creating data loader objects that'll supply batches of data to our model\n",
        "train = DataLoader(dataset = train_data, sampler = RandomSampler(train_data), batch_size = 16)\n",
        "test = DataLoader(dataset = test_data, batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.72 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dbsrTAIvni",
        "outputId": "88b916bc-0c20-490d-e8d0-ea6ac75bffb2"
      },
      "source": [
        "# Defining the Classification Neural Network: 1 input layer, 1 hidden layer, 1 output layer\n",
        "class ClassificationNN(nn.Module):\n",
        "  # Defining our neural network architecture in the constructor \n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    # Calling the correct parent constructors in the MRO\n",
        "    super().__init__()\n",
        "\n",
        "    self.input1 = nn.Linear(in_features = input_dim, out_features = 100)\n",
        "    self.hidden2 = nn.Linear(in_features = 100, out_features = 200)\n",
        "    self.output3 = nn.Linear(in_features = 200, out_features = output_dim)\n",
        "\n",
        "  # Defining forward pass computations\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = self.output3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Creating an object of our neural network class\n",
        "input_dim = len(X_train[0])\n",
        "output_dim = 1\n",
        "\n",
        "model = ClassificationNN(input_dim = input_dim, output_dim = output_dim)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClassificationNN(\n",
            "  (input1): Linear(in_features=9, out_features=100, bias=True)\n",
            "  (hidden2): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (output3): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zcs_pqNaoaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a548415-b514-4203-b21f-f1f4ed38df44"
      },
      "source": [
        "# Optimizer\n",
        "%time\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(params = model.parameters(), lr = 0.02, eps = 2e-3, amsgrad = True)\n",
        "\n",
        "# Loss Function: Cross Entropy Loss\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOxSAl3vr8lB",
        "outputId": "05932251-767d-4354-d58d-bd779248fbcd"
      },
      "source": [
        "# Training loop\n",
        "%time\n",
        "\n",
        "# Putting model in train mode\n",
        "model.train()\n",
        "\n",
        "# Epochs \n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "  print('------------')\n",
        "\n",
        "  # Calculating training loss for every epoch\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # Training batches\n",
        "  for features, target in train:\n",
        "    \n",
        "    # Push variables to device\n",
        "    features, target = features.to(device), target.to(device)\n",
        "\n",
        "    # Clear out gradients from previous training batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass; feed inputs to model & get outputs\n",
        "    outputs = model(features)\n",
        "    \n",
        "    # Calculate loss between model's predictions & actual target\n",
        "    loss = criterion(outputs, target)\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Back propagate loss throughout the neural network\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on the current gradient\n",
        "    optimizer.step()\n",
        "  \n",
        "  print('Training Loss: ', train_loss/len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n",
            "\n",
            "Epoch 1/20\n",
            "------------\n",
            "Training Loss:  0.3237581169931218\n",
            "\n",
            "Epoch 2/20\n",
            "------------\n",
            "Training Loss:  0.19171019072333972\n",
            "\n",
            "Epoch 3/20\n",
            "------------\n",
            "Training Loss:  0.1645514545030892\n",
            "\n",
            "Epoch 4/20\n",
            "------------\n",
            "Training Loss:  0.14227132067705195\n",
            "\n",
            "Epoch 5/20\n",
            "------------\n",
            "Training Loss:  0.14220010687907536\n",
            "\n",
            "Epoch 6/20\n",
            "------------\n",
            "Training Loss:  0.1531794733988742\n",
            "\n",
            "Epoch 7/20\n",
            "------------\n",
            "Training Loss:  0.14538309685885906\n",
            "\n",
            "Epoch 8/20\n",
            "------------\n",
            "Training Loss:  0.12394413854926825\n",
            "\n",
            "Epoch 9/20\n",
            "------------\n",
            "Training Loss:  0.1244189123933514\n",
            "\n",
            "Epoch 10/20\n",
            "------------\n",
            "Training Loss:  0.11477905033777157\n",
            "\n",
            "Epoch 11/20\n",
            "------------\n",
            "Training Loss:  0.12007809989154339\n",
            "\n",
            "Epoch 12/20\n",
            "------------\n",
            "Training Loss:  0.11955614139636357\n",
            "\n",
            "Epoch 13/20\n",
            "------------\n",
            "Training Loss:  0.11661903696755568\n",
            "\n",
            "Epoch 14/20\n",
            "------------\n",
            "Training Loss:  0.11131213294963042\n",
            "\n",
            "Epoch 15/20\n",
            "------------\n",
            "Training Loss:  0.11643943358212709\n",
            "\n",
            "Epoch 16/20\n",
            "------------\n",
            "Training Loss:  0.10745923817157746\n",
            "\n",
            "Epoch 17/20\n",
            "------------\n",
            "Training Loss:  0.11752936448901892\n",
            "\n",
            "Epoch 18/20\n",
            "------------\n",
            "Training Loss:  0.11071712970733642\n",
            "\n",
            "Epoch 19/20\n",
            "------------\n",
            "Training Loss:  0.10845247097313404\n",
            "\n",
            "Epoch 20/20\n",
            "------------\n",
            "Training Loss:  0.12665808523694674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipLOg12auh3j",
        "outputId": "8cc60145-0ac4-4aa3-df87-c0d189ca0f29"
      },
      "source": [
        "# Testing loop\n",
        "%time\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Putting model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Disabling gradient calculation with no_grad(). Deactivates auto_grad engine \n",
        "# and reduces memory usage and speeds up computations but back propagation not possible.\n",
        "with torch.no_grad():\n",
        "  for features, target in test:\n",
        "\n",
        "    # Pushing data to the device\n",
        "    features = features.to(device)\n",
        "\n",
        "    # Perform forward pass, collect outputs\n",
        "    output = model(features)\n",
        "\n",
        "    # Deatch predictions from the graph and append to list\n",
        "    preds.append(output.detach().cpu().numpy())\n",
        "    targets.append(target.numpy())\n",
        "\n",
        "# Converting preds to a simple list from a list of arrays\n",
        "preds = [0 if x[0][0] < 0 else 1 for x in preds]\n",
        "y_test = [x for x in y_test]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 8.58 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsAgYAL8vkl_",
        "outputId": "2332099b-f532-44f8-f3d5-dde31d25c341"
      },
      "source": [
        "# Calculating accuracy between predictions & target\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pprint import pprint\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "report = classification_report(y_test, preds)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc, report))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UAXG0R2Hzca"
      },
      "source": [
        "## **4) Keras Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjyN9VvH5uu",
        "outputId": "93b1036e-cb0e-4b71-ea0f-002b94f926e9"
      },
      "source": [
        "# Importing keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "regressor = Sequential()\n",
        "regressor.add(Dense(units = 100, activation = 'relu', input_dim = input_dim))\n",
        "regressor.add(Dense(units = 200, activation = 'relu'))\n",
        "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the model with adam optimizer\n",
        "regressor.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')\n",
        "\n",
        "# Training the model\n",
        "history = regressor.fit(X_train, y_train, batch_size = 16, epochs = 20, verbose = 0)\n",
        "\n",
        "# Evaluating on test set\n",
        "y_pred = regressor.predict_classes(X_test)\n",
        "\n",
        "# Printing metrics\n",
        "acc_k = accuracy_score(y_test, y_pred)\n",
        "report_k = classification_report(y_test, y_pred)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc_k, report_k))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xqemUMkOCUJ"
      },
      "source": [
        "## **5) TensorFlow Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnNXyB0DOB6o"
      },
      "source": [
        "# Converting numpy arrays to tf dataset\n",
        "import tensorflow as tf\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_data = train_data.batch(batch_size = 16)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_data = test_data.batch(batch_size = len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhUXqSwVPTJr"
      },
      "source": [
        "# Creating a classification neural network\n",
        "from tensorflow.keras import Model, losses, metrics, optimizers, activations\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Classification class\n",
        "class Classification(Model):\n",
        "  # Defining layer architectures in the constructor\n",
        "  def __init__(self):\n",
        "    # Calling the correct parent constructors in the Method Resolution Order\n",
        "    super().__init__()\n",
        "\n",
        "    self.input1 = Dense(units = 100, activation = activations.relu)\n",
        "    self.hidden2 = Dense(units = 200, activation = activations.relu)\n",
        "    self.output3 = Dense(units = 1, activation = activations.hard_sigmoid)\n",
        "  \n",
        "  # Defining forward pass computations\n",
        "  def call(self, x):\n",
        "    x = self.input1(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.output3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Creating an instance of the classification neural network\n",
        "model = Classification()\n",
        "\n",
        "# Setting up optimizers\n",
        "optimizer = optimizers.Adam(learning_rate = 0.01, epsilon = 2e-3)\n",
        "\n",
        "# Loss object\n",
        "loss_object = losses.BinaryCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilQWI-PPckb1",
        "outputId": "f9a5cb67-3c62-4c1d-d7d5-950c69f7aa5a"
      },
      "source": [
        "# Training loop\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "  print('-----------')\n",
        "\n",
        "  # Training loss for every epoch\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # Iterating over batches in training dataset\n",
        "  for x, y in train_data:\n",
        "\n",
        "    # Using tf.GradientTape() to record forward pass computations on the trainable weights & enable auto-differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Feed inputs to model; perform forward pass\n",
        "      outputs = model(x)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = loss_object(y, outputs)\n",
        "      train_loss += loss\n",
        "\n",
        "    # Calculate gradients of the trainable model parameters w.r.t loss \n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "\n",
        "    # Applying one step of gradient descent to minimize loss by updating the weights\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "  # Printing avg train loss after every epoch\n",
        "  print('Average train loss: {}\\n'.format(train_loss/len(train_data)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "-----------\n",
            "Average train loss: 0.5607510805130005\n",
            "\n",
            "Epoch 2/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 3/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 4/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 5/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 6/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 7/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 8/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 9/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 10/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 11/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 12/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 13/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 14/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 15/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 16/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 17/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 18/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 19/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n",
            "Epoch 20/20\n",
            "-----------\n",
            "Average train loss: 0.5784355998039246\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKVctQFvqrrb",
        "outputId": "f5a80324-b730-4671-d197-cb20844ae69d"
      },
      "source": [
        "# Testing loop\n",
        "# Setting accuracy as the metric for evaluating performance of the model\n",
        "accuracy = metrics.Accuracy()\n",
        "precision = metrics.Precision()\n",
        "recall = metrics.Recall()\n",
        "\n",
        "for x, y in test_data:\n",
        "  # Feed inputs to the model, collect outputs\n",
        "  output = model(x)\n",
        "  print((output, y))\n",
        "  # Calculate accuracy, precision & recall\n",
        "  accuracy.update_state(y, output)\n",
        "  precision.update_state(y, output)\n",
        "  recall.update_state(y, output)\n",
        "\n",
        "  # Extract only the numpy value\n",
        "  acc = accuracy.result().numpy()\n",
        "  prec = precision.result().numpy()\n",
        "  rec = recall.result().numpy()\n",
        "\n",
        "# Printing metrics\n",
        "print('Performance of TensorFlow Model\\n\\nAccuracy: {}\\nPrecision: {}\\nRecall: {}\\n'.format(acc, prec, rec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(60, 1), dtype=float32, numpy=\n",
            "array([[0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.]], dtype=float32)>, <tf.Tensor: shape=(60, 1), dtype=int64, numpy=\n",
            "array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]])>)\n",
            "Performance of TensorFlow Model\n",
            "\n",
            "Accuracy: 0.9833333492279053\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEGCjJStwUD_",
        "outputId": "d002c317-e469-48f8-a815-aae8ab7083e6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}