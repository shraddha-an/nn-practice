{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_owner_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZP7TFXgXZRPEfeWb1nNw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/nn-practice/blob/main/car_owner_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1sAue48tVB"
      },
      "source": [
        "# **Classifying number of car owners with Classification Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhUVXHd-8-Md"
      },
      "source": [
        "## **1) Importing libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIjXt0L6ogt"
      },
      "source": [
        "# Importing required libraries\n",
        "# Data Handling/ Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Time \n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnfKfFB-G8W"
      },
      "source": [
        "## **2) Data Preprocessing**\n",
        "---\n",
        "**Steps:**\n",
        "\n",
        "1) Columns to encode: Fuel_Type, Seller_Type, Transmission\n",
        "\n",
        "2) Feature Extraction: Extract Age of the vehicle from the Year column\n",
        "\n",
        "3) Columns to delete: Car_Name, Year.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_haD_owD9-W-",
        "outputId": "45b022d0-ffc1-4df9-8783-d5439b980298"
      },
      "source": [
        "# Importing dataset\n",
        "dataset = pd.read_csv('car_data.csv')\n",
        "\n",
        "# Calculating age in years of each vehicle\n",
        "dataset['Age'] = dataset['Year'].apply(lambda x: dt.today().year - x)\n",
        "\n",
        "# Deleting car name & year columns\n",
        "dataset.drop(columns = ['Car_Name', 'Year'], inplace = True)\n",
        "\n",
        "# Deleting the row where owner = 3 as only 1 example exists in the dataset\n",
        "dataset = dataset[dataset['Owner'] != 3]\n",
        "print(len(dataset))\n",
        "\n",
        "# Splitting into feature & target matrices\n",
        "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5, 7]].values\n",
        "y = dataset.iloc[:, -2].values.reshape(-1, 1)\n",
        "\n",
        "# Splitting into train & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240, 7), (240, 1), (60, 7), (60, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJto-i-6MIQK",
        "outputId": "3595f7dd-6ba8-4d45-e312-98bfea35a56a"
      },
      "source": [
        "X_train[98]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.1, 4.43, 11849, 'Petrol', 'Dealer', 'Manual', 5], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZ0ZZkaGvyG",
        "outputId": "c2efcc30-b028-4670-83a9-6b0cf0b51774"
      },
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer \n",
        "\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train[:, 3] = enc.fit_transform(X_train[:, 3])\n",
        "X_test[:, 3] = enc.transform(X_test[:, 3])\n",
        "\n",
        "X_train[:, 4] = enc.fit_transform(X_train[:, 4])\n",
        "X_test[:, 4] = enc.transform(X_test[:, 4])\n",
        "\n",
        "X_train[:, 5] = enc.fit_transform(X_train[:, 5])\n",
        "X_test[:, 5] = enc.transform(X_test[:, 5])\n",
        "\n",
        "# OHE the Fuel_Type column\n",
        "ohe = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder = 'passthrough') \n",
        "\n",
        "X_train = ohe.fit_transform(X_train)\n",
        "X_test = ohe.transform(X_test)\n",
        "\n",
        "\n",
        "# Also label encoding the output classes from [0, 1, 3] to [0, 1, 2]\n",
        "y_train[:, 0] = enc.fit_transform(y_train[:, 0])\n",
        "y_test[:, 0] = enc.transform(y_test[:, 0])\n",
        "\n",
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "len(X_test[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4ohkbzH03v"
      },
      "source": [
        "## **3) PyTorch Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aNk4ro7H0nf",
        "outputId": "6ab59907-7a98-47cb-8d3e-71b306e216bc"
      },
      "source": [
        "# Converting numpy arrays to torch tensors of dtype float32\n",
        "%time\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32))\n",
        "test_data = TensorDataset(torch.tensor(X_test, dtype = torch.float32), torch.tensor(y_test, dtype = torch.float32))\n",
        "\n",
        "# Creating data loader objects that'll supply batches of data to our model\n",
        "train = DataLoader(dataset = train_data, sampler = RandomSampler(train_data), batch_size = 16)\n",
        "test = DataLoader(dataset = test_data, batch_size = 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15 µs, sys: 3 µs, total: 18 µs\n",
            "Wall time: 23.6 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dbsrTAIvni",
        "outputId": "1f6c3b5c-e134-43b0-e511-7338b092ac9b"
      },
      "source": [
        "# Defining the Classification Neural Network: 1 input layer, 1 hidden layer, 1 output layer\n",
        "class ClassificationNN(nn.Module):\n",
        "  # Defining our neural network architecture in the constructor \n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    # Calling the correct parent constructors in the MRO\n",
        "    super().__init__()\n",
        "\n",
        "    self.input1 = nn.Linear(in_features = input_dim, out_features = 100)\n",
        "    self.hidden2 = nn.Linear(in_features = 100, out_features = 200)\n",
        "    self.output3 = nn.Linear(in_features = 200, out_features = output_dim)\n",
        "\n",
        "  # Defining forward pass computations\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = self.output3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Creating an object of our neural network class\n",
        "input_dim = len(X_train[0])\n",
        "output_dim = 1\n",
        "\n",
        "model = ClassificationNN(input_dim = input_dim, output_dim = output_dim)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClassificationNN(\n",
            "  (input1): Linear(in_features=9, out_features=100, bias=True)\n",
            "  (hidden2): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (output3): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zcs_pqNaoaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308e84d4-eaa5-41da-adc6-8cf278c1129e"
      },
      "source": [
        "# Optimizer\n",
        "%time\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(params = model.parameters(), lr = 0.02, eps = 2e-3, amsgrad = True)\n",
        "\n",
        "# Loss Function: Cross Entropy Loss\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 6.91 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOxSAl3vr8lB",
        "outputId": "8a4ba210-bd6c-40c3-fa9b-17c70b8ddf20"
      },
      "source": [
        "# Training loop\n",
        "%time\n",
        "\n",
        "# Putting model in train mode\n",
        "model.train()\n",
        "\n",
        "# Epochs \n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "  print('------------')\n",
        "\n",
        "  # Calculating training loss for every epoch\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # Training batches\n",
        "  for features, target in train:\n",
        "    \n",
        "    # Push variables to device\n",
        "    features, target = features.to(device), target.to(device)\n",
        "\n",
        "    # Clear out gradients from previous training batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass; feed inputs to model & get outputs\n",
        "    outputs = model(features)\n",
        "    \n",
        "    # Calculate loss between model's predictions & actual target\n",
        "    loss = criterion(outputs, target)\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Back propagate loss throughout the neural network\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on the current gradient\n",
        "    optimizer.step()\n",
        "  \n",
        "  print('Training Loss: ', train_loss/len(train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.01 µs\n",
            "\n",
            "Epoch 1/20\n",
            "------------\n",
            "Training Loss:  0.1055546243985494\n",
            "\n",
            "Epoch 2/20\n",
            "------------\n",
            "Training Loss:  0.09961464814841747\n",
            "\n",
            "Epoch 3/20\n",
            "------------\n",
            "Training Loss:  0.10121474266052247\n",
            "\n",
            "Epoch 4/20\n",
            "------------\n",
            "Training Loss:  0.11287110920529812\n",
            "\n",
            "Epoch 5/20\n",
            "------------\n",
            "Training Loss:  0.10627344325184822\n",
            "\n",
            "Epoch 6/20\n",
            "------------\n",
            "Training Loss:  0.10639786271688839\n",
            "\n",
            "Epoch 7/20\n",
            "------------\n",
            "Training Loss:  0.09424895333747069\n",
            "\n",
            "Epoch 8/20\n",
            "------------\n",
            "Training Loss:  0.10187085202584664\n",
            "\n",
            "Epoch 9/20\n",
            "------------\n",
            "Training Loss:  0.09419035129249095\n",
            "\n",
            "Epoch 10/20\n",
            "------------\n",
            "Training Loss:  0.09847025039295355\n",
            "\n",
            "Epoch 11/20\n",
            "------------\n",
            "Training Loss:  0.09182608059297005\n",
            "\n",
            "Epoch 12/20\n",
            "------------\n",
            "Training Loss:  0.09331083226328095\n",
            "\n",
            "Epoch 13/20\n",
            "------------\n",
            "Training Loss:  0.09494262840598822\n",
            "\n",
            "Epoch 14/20\n",
            "------------\n",
            "Training Loss:  0.08601976707577705\n",
            "\n",
            "Epoch 15/20\n",
            "------------\n",
            "Training Loss:  0.1127285633100352\n",
            "\n",
            "Epoch 16/20\n",
            "------------\n",
            "Training Loss:  0.09163732876380284\n",
            "\n",
            "Epoch 17/20\n",
            "------------\n",
            "Training Loss:  0.09392077041169007\n",
            "\n",
            "Epoch 18/20\n",
            "------------\n",
            "Training Loss:  0.09299371677140394\n",
            "\n",
            "Epoch 19/20\n",
            "------------\n",
            "Training Loss:  0.08668408611944566\n",
            "\n",
            "Epoch 20/20\n",
            "------------\n",
            "Training Loss:  0.10081741788114111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipLOg12auh3j",
        "outputId": "05247ca9-2543-4805-8028-063eb7939098"
      },
      "source": [
        "# Testing loop\n",
        "%time\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Putting model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Disabling gradient calculation with no_grad(). Deactivates auto_grad engine \n",
        "# and reduces memory usage and speeds up computations but back propagation not possible.\n",
        "with torch.no_grad():\n",
        "  for features, target in test:\n",
        "\n",
        "    # Pushing data to the device\n",
        "    features = features.to(device)\n",
        "\n",
        "    # Perform forward pass, collect outputs\n",
        "    output = model(features)\n",
        "\n",
        "    # Deatch predictions from the graph and append to list\n",
        "    preds.append(output.detach().cpu().numpy())\n",
        "    targets.append(target.numpy())\n",
        "\n",
        "# Converting preds to a simple list from a list of arrays\n",
        "preds = [0 if x[0][0] < 0 else 1 for x in preds]\n",
        "y_test = [x for x in y_test]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.01 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsAgYAL8vkl_",
        "outputId": "1ff35678-0793-414a-c037-32e2167307cc"
      },
      "source": [
        "# Calculating MAE between predictions & target\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pprint import pprint\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "report = classification_report(y_test, preds)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc, report))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.97        60\n",
            "   macro avg       0.49      0.49      0.49        60\n",
            "weighted avg       0.97      0.97      0.97        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UAXG0R2Hzca"
      },
      "source": [
        "## **4) Keras Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjyN9VvH5uu",
        "outputId": "b10336f6-e14c-4029-f707-0824ea63ef31"
      },
      "source": [
        "# Importing keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "regressor = Sequential()\n",
        "regressor.add(Dense(units = 100, activation = 'relu', input_dim = input_dim))\n",
        "regressor.add(Dense(units = 200, activation = 'relu'))\n",
        "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the model with adam optimizer\n",
        "regressor.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')\n",
        "\n",
        "# Training the model\n",
        "history = regressor.fit(X_train, y_train, batch_size = 16, epochs = 20, verbose = 0)\n",
        "\n",
        "# Evaluating on test set\n",
        "y_pred = regressor.predict_classes(X_test)\n",
        "\n",
        "# Printing metrics\n",
        "acc_k = accuracy_score(y_test, y_pred)\n",
        "report_k = classification_report(y_test, y_pred)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc_k, report_k))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}