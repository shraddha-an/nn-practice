{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_owner_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9kNb9fWxZKAQsIkjKJPzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/nn-practice/blob/main/car_owner_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1sAue48tVB"
      },
      "source": [
        "# **Classifying number of car owners with Classification Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhUVXHd-8-Md"
      },
      "source": [
        "## **1) Importing libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIjXt0L6ogt"
      },
      "source": [
        "# Importing required libraries\n",
        "# Data Handling/ Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Time \n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnfKfFB-G8W"
      },
      "source": [
        "## **2) Data Preprocessing**\n",
        "---\n",
        "**Steps:**\n",
        "\n",
        "1) Columns to encode: Fuel_Type, Seller_Type, Transmission\n",
        "\n",
        "2) Feature Extraction: Extract Age of the vehicle from the Year column\n",
        "\n",
        "3) Columns to delete: Car_Name, Year.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_haD_owD9-W-",
        "outputId": "ec7696a7-8f38-4384-9388-cd3ba18d7a8e"
      },
      "source": [
        "# Importing dataset\n",
        "dataset = pd.read_csv('car_data.csv')\n",
        "\n",
        "# Calculating age in years of each vehicle\n",
        "dataset['Age'] = dataset['Year'].apply(lambda x: dt.today().year - x)\n",
        "\n",
        "# Deleting car name & year columns\n",
        "dataset.drop(columns = ['Car_Name', 'Year'], inplace = True)\n",
        "\n",
        "# Deleting the row where owner = 3 as only 1 example exists in the dataset\n",
        "dataset = dataset[dataset['Owner'] != 3]\n",
        "print(len(dataset))\n",
        "\n",
        "# Splitting into feature & target matrices\n",
        "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5, 7]].values\n",
        "y = dataset.iloc[:, -2].values.reshape(-1, 1)\n",
        "\n",
        "# Splitting into train & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240, 7), (240, 1), (60, 7), (60, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJto-i-6MIQK",
        "outputId": "2f418bdb-f818-41ab-f154-b147250776d4"
      },
      "source": [
        "dataset['Owner'].value_counts()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    290\n",
              "1     10\n",
              "Name: Owner, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZ0ZZkaGvyG",
        "outputId": "32965c96-4f5b-4c09-dc23-ddfda914ccb2"
      },
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train[:, 3] = enc.fit_transform(X_train[:, 3])\n",
        "X_test[:, 3] = enc.transform(X_test[:, 3])\n",
        "\n",
        "X_train[:, 4] = enc.fit_transform(X_train[:, 4])\n",
        "X_test[:, 4] = enc.transform(X_test[:, 4])\n",
        "\n",
        "X_train[:, 5] = enc.fit_transform(X_train[:, 5])\n",
        "X_test[:, 5] = enc.transform(X_test[:, 5])\n",
        "\n",
        "# Also label encoding the output classes from [0, 1, 3] to [0, 1, 2]\n",
        "y_train[:, 0] = enc.fit_transform(y_train[:, 0])\n",
        "y_test[:, 0] = enc.transform(y_test[:, 0])\n",
        "\n",
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "len(X_test[0])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4ohkbzH03v"
      },
      "source": [
        "## **3) PyTorch Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aNk4ro7H0nf",
        "outputId": "d24bd9c2-34e0-4011-9b22-489358990649"
      },
      "source": [
        "# Converting numpy arrays to torch tensors of dtype float32\n",
        "%time\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32))\n",
        "test_data = TensorDataset(torch.tensor(X_test, dtype = torch.float32), torch.tensor(y_test, dtype = torch.float32))\n",
        "\n",
        "# Creating data loader objects that'll supply batches of data to our model\n",
        "train = DataLoader(dataset = train_data, sampler = RandomSampler(train_data), batch_size = 16)\n",
        "test = DataLoader(dataset = test_data, batch_size = 1)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dbsrTAIvni",
        "outputId": "272b4491-804a-43fd-8a83-82fb124d0597"
      },
      "source": [
        "# Defining the Classification Neural Network: 1 input layer, 1 hidden layer, 1 output layer\n",
        "class ClassificationNN(nn.Module):\n",
        "  # Defining our neural network architecture in the constructor \n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    # Calling the correct parent constructors in the MRO\n",
        "    super().__init__()\n",
        "\n",
        "    self.input1 = nn.Linear(in_features = input_dim, out_features = 100)\n",
        "    self.hidden2 = nn.Linear(in_features = 100, out_features = 200)\n",
        "    self.output3 = nn.Linear(in_features = 200, out_features = output_dim)\n",
        "\n",
        "  # Defining forward pass computations\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = self.output3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Creating an object of our neural network class\n",
        "input_dim = len(X_train[0])\n",
        "output_dim = 1\n",
        "\n",
        "model = ClassificationNN(input_dim = input_dim, output_dim = output_dim)\n",
        "print(model)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClassificationNN(\n",
            "  (input1): Linear(in_features=7, out_features=100, bias=True)\n",
            "  (hidden2): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (output3): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zcs_pqNaoaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e1fc52-3740-440f-9979-fcd2c0483088"
      },
      "source": [
        "# Optimizer\n",
        "%time\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(params = model.parameters(), lr = 0.02, eps = 2e-3, amsgrad = True)\n",
        "\n",
        "# Creating a (1,3) weight tensor for my classes\n",
        "class_counts = dict(dataset['Owner'].value_counts())\n",
        "instances = sum([p[x] for x in class_counts])\n",
        "\n",
        "weights = torch.tensor([instances/p[x] for x in class_counts], dtype = torch.float32)\n",
        "\n",
        "# Loss Function: Cross Entropy Loss\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 4 µs, total: 4 µs\n",
            "Wall time: 8.11 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOxSAl3vr8lB",
        "outputId": "32d13e65-a747-4244-8361-366ded99b877"
      },
      "source": [
        "# Training loop\n",
        "%time\n",
        "\n",
        "# Putting model in train mode\n",
        "model.train()\n",
        "\n",
        "# Loss variable\n",
        "train_loss = 0.0\n",
        "\n",
        "# Epochs \n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "  print('------------')\n",
        "\n",
        "  # Training batches\n",
        "  for features, target in train:\n",
        "    \n",
        "    # Push variables to device\n",
        "    features, target = features.to(device), target.to(device)\n",
        "\n",
        "    # Clear out gradients from previous training batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass; feed inputs to model & get outputs\n",
        "    outputs = model(features)\n",
        "    \n",
        "    # Calculate loss between model's predictions & actual target\n",
        "    loss = criterion(outputs, target)\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Back propagate loss throughout the neural network\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on the current gradient\n",
        "    optimizer.step()\n",
        "  \n",
        "  print('Training Loss: ', train_loss/len(train))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.96 µs\n",
            "\n",
            "Epoch 1/20\n",
            "------------\n",
            "Training Loss:  0.35339458236315596\n",
            "\n",
            "Epoch 2/20\n",
            "------------\n",
            "Training Loss:  0.5309721154393628\n",
            "\n",
            "Epoch 3/20\n",
            "------------\n",
            "Training Loss:  0.679834539652802\n",
            "\n",
            "Epoch 4/20\n",
            "------------\n",
            "Training Loss:  0.8164396489271895\n",
            "\n",
            "Epoch 5/20\n",
            "------------\n",
            "Training Loss:  0.9476091908523813\n",
            "\n",
            "Epoch 6/20\n",
            "------------\n",
            "Training Loss:  1.0785427916406964\n",
            "\n",
            "Epoch 7/20\n",
            "------------\n",
            "Training Loss:  1.2043298196901258\n",
            "\n",
            "Epoch 8/20\n",
            "------------\n",
            "Training Loss:  1.3275671418989077\n",
            "\n",
            "Epoch 9/20\n",
            "------------\n",
            "Training Loss:  1.4462630874399716\n",
            "\n",
            "Epoch 10/20\n",
            "------------\n",
            "Training Loss:  1.560950763671038\n",
            "\n",
            "Epoch 11/20\n",
            "------------\n",
            "Training Loss:  1.6756663942942396\n",
            "\n",
            "Epoch 12/20\n",
            "------------\n",
            "Training Loss:  1.7990481526513273\n",
            "\n",
            "Epoch 13/20\n",
            "------------\n",
            "Training Loss:  1.9121632596710696\n",
            "\n",
            "Epoch 14/20\n",
            "------------\n",
            "Training Loss:  2.0260792491569495\n",
            "\n",
            "Epoch 15/20\n",
            "------------\n",
            "Training Loss:  2.142958959712026\n",
            "\n",
            "Epoch 16/20\n",
            "------------\n",
            "Training Loss:  2.2521014995484925\n",
            "\n",
            "Epoch 17/20\n",
            "------------\n",
            "Training Loss:  2.3579529045382515\n",
            "\n",
            "Epoch 18/20\n",
            "------------\n",
            "Training Loss:  2.479391547998724\n",
            "\n",
            "Epoch 19/20\n",
            "------------\n",
            "Training Loss:  2.5854985036809617\n",
            "\n",
            "Epoch 20/20\n",
            "------------\n",
            "Training Loss:  2.686720734174984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipLOg12auh3j",
        "outputId": "7bcff6b6-6f11-48b5-8176-64c6c07410a7"
      },
      "source": [
        "# Testing loop\n",
        "%time\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Putting model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Disabling gradient calculation with no_grad(). Deactivates auto_grad engine \n",
        "# and reduces memory usage and speeds up computations but back propagation not possible.\n",
        "with torch.no_grad():\n",
        "  for features, target in test:\n",
        "\n",
        "    # Pushing data to the device\n",
        "    features = features.to(device)\n",
        "\n",
        "    # Perform forward pass, collect outputs\n",
        "    output = model(features)\n",
        "\n",
        "    # Deatch predictions from the graph and append to list\n",
        "    preds.append(output.detach().cpu().numpy())\n",
        "    targets.append(target.numpy())\n",
        "\n",
        "# Converting preds to a simple list from a list of arrays\n",
        "preds = [0 if x[0][0] < 0 else 1 for x in preds]\n",
        "y_test = [x for x in y_test]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsAgYAL8vkl_",
        "outputId": "4ffb08b1-7967-48c8-d558-cc03685b85a8"
      },
      "source": [
        "# Calculating MAE between predictions & target\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pprint import pprint\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "report = classification_report(y_test, preds)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc, report))\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UAXG0R2Hzca"
      },
      "source": [
        "## **4) Keras Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjyN9VvH5uu",
        "outputId": "a5a0f6dc-217c-4003-b231-918e7e4af2a1"
      },
      "source": [
        "# Importing keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "regressor = Sequential()\n",
        "regressor.add(Dense(units = 100, activation = 'relu', input_dim = input_dim))\n",
        "regressor.add(Dense(units = 200, activation = 'relu'))\n",
        "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the model with adam optimizer\n",
        "regressor.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')\n",
        "\n",
        "# Training the model\n",
        "history = regressor.fit(X_train, y_train, batch_size = 16, epochs = 20, verbose = 0)\n",
        "\n",
        "# Evaluating on test set\n",
        "y_pred = regressor.predict_classes(X_test)\n",
        "\n",
        "# Printing metrics\n",
        "acc_k = accuracy_score(y_test, y_pred)\n",
        "report_k = classification_report(y_test, y_pred)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc_k, report_k))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3e5c7f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}