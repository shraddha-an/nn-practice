{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_owner_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOL06otvynhuiO3iYNymJZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/nn-practice/blob/main/car_owner_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1sAue48tVB"
      },
      "source": [
        "# **Classifying number of car owners with Classification Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhUVXHd-8-Md"
      },
      "source": [
        "## **1) Importing libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIjXt0L6ogt"
      },
      "source": [
        "# Importing required libraries\n",
        "# Data Handling/ Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Time \n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnfKfFB-G8W"
      },
      "source": [
        "## **2) Data Preprocessing**\n",
        "---\n",
        "**Steps:**\n",
        "\n",
        "1) Columns to encode: Fuel_Type, Seller_Type, Transmission\n",
        "\n",
        "2) Feature Extraction: Extract Age of the vehicle from the Year column\n",
        "\n",
        "3) Columns to delete: Car_Name, Year.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_haD_owD9-W-",
        "outputId": "532ee5c7-ecf0-402d-a128-f6b8fec004c5"
      },
      "source": [
        "# Importing dataset\n",
        "dataset = pd.read_csv('car_data.csv')\n",
        "\n",
        "# Calculating age in years of each vehicle\n",
        "dataset['Age'] = dataset['Year'].apply(lambda x: dt.today().year - x)\n",
        "\n",
        "# Deleting car name & year columns\n",
        "dataset.drop(columns = ['Car_Name', 'Year'], inplace = True)\n",
        "\n",
        "# Deleting the row where owner = 3 as only 1 example exists in the dataset\n",
        "dataset = dataset[dataset['Owner'] != 3]\n",
        "print(len(dataset))\n",
        "\n",
        "# Splitting into feature & target matrices\n",
        "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5, 7]].values\n",
        "y = dataset.iloc[:, -2].values.reshape(-1, 1)\n",
        "\n",
        "# Splitting into train & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240, 7), (240, 1), (60, 7), (60, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJto-i-6MIQK",
        "outputId": "850b98a0-0878-41fa-da55-b184ec88a44a"
      },
      "source": [
        "dataset['Owner'].value_counts()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    290\n",
              "1     10\n",
              "Name: Owner, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZ0ZZkaGvyG",
        "outputId": "3f851bbb-0e4e-4dd0-c065-a27fac0ee766"
      },
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train[:, 3] = enc.fit_transform(X_train[:, 3])\n",
        "X_test[:, 3] = enc.transform(X_test[:, 3])\n",
        "\n",
        "X_train[:, 4] = enc.fit_transform(X_train[:, 4])\n",
        "X_test[:, 4] = enc.transform(X_test[:, 4])\n",
        "\n",
        "X_train[:, 5] = enc.fit_transform(X_train[:, 5])\n",
        "X_test[:, 5] = enc.transform(X_test[:, 5])\n",
        "\n",
        "# Also label encoding the output classes from [0, 1, 3] to [0, 1, 2]\n",
        "y_train[:, 0] = enc.fit_transform(y_train[:, 0])\n",
        "y_test[:, 0] = enc.transform(y_test[:, 0])\n",
        "\n",
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "len(X_test[0])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4ohkbzH03v"
      },
      "source": [
        "## **3) PyTorch Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aNk4ro7H0nf",
        "outputId": "b102be06-0182-4750-803a-b6a7a3235a3f"
      },
      "source": [
        "# Converting numpy arrays to torch tensors of dtype float32\n",
        "%time\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32))\n",
        "test_data = TensorDataset(torch.tensor(X_test, dtype = torch.float32), torch.tensor(y_test, dtype = torch.float32))\n",
        "\n",
        "# Creating data loader objects that'll supply batches of data to our model\n",
        "train = DataLoader(dataset = train_data, sampler = RandomSampler(train_data), batch_size = 16)\n",
        "test = DataLoader(dataset = test_data, batch_size = 1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 4.77 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dbsrTAIvni",
        "outputId": "289ddab7-300c-4887-b7dc-73013e9c1ce6"
      },
      "source": [
        "# Defining the Classification Neural Network: 1 input layer, 1 hidden layer, 1 output layer\n",
        "class ClassificationNN(nn.Module):\n",
        "  # Defining our neural network architecture in the constructor \n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    # Calling the correct parent constructors in the MRO\n",
        "    super().__init__()\n",
        "\n",
        "    self.input1 = nn.Linear(in_features = input_dim, out_features = 100)\n",
        "    self.hidden2 = nn.Linear(in_features = 100, out_features = 200)\n",
        "    self.output3 = nn.Linear(in_features = 200, out_features = output_dim)\n",
        "\n",
        "  # Defining forward pass computations\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = self.output3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Creating an object of our neural network class\n",
        "input_dim = len(X_train[0])\n",
        "output_dim = 1\n",
        "\n",
        "model = ClassificationNN(input_dim = input_dim, output_dim = output_dim)\n",
        "print(model)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClassificationNN(\n",
            "  (input1): Linear(in_features=7, out_features=100, bias=True)\n",
            "  (hidden2): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (output3): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zcs_pqNaoaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebedfe8-5388-4ad9-90b7-8c27181335ed"
      },
      "source": [
        "# Optimizer\n",
        "%time\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(params = model.parameters(), lr = 0.02, eps = 2e-3, amsgrad = True)\n",
        "\n",
        "# Creating a (1,3) weight tensor for my classes\n",
        "class_counts = dict(dataset['Owner'].value_counts())\n",
        "instances = sum([p[x] for x in class_counts])\n",
        "\n",
        "weights = torch.tensor([instances/p[x] for x in class_counts], dtype = torch.float32)\n",
        "\n",
        "# Loss Function: Cross Entropy Loss. Specifying a weight tensor as my classes are imbalanced.\n",
        "# reduction = 'mean' as I have not normalized these weights (add up to 1)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 8.11 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94kf5cHldgJ6",
        "outputId": "aa4788c6-7718-45dd-e644-21ba0d476629"
      },
      "source": [
        "weights"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0345, 30.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOxSAl3vr8lB",
        "outputId": "1fd265cb-8d6b-45f8-808e-644478feab1a"
      },
      "source": [
        "# Training loop\n",
        "%time\n",
        "\n",
        "# Putting model in train mode\n",
        "model.train()\n",
        "\n",
        "# Loss variable\n",
        "train_loss = 0.0\n",
        "\n",
        "# Epochs \n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "  print('------------')\n",
        "\n",
        "  # Training batches\n",
        "  for features, target in train:\n",
        "    \n",
        "    # Push variables to device\n",
        "    features, target = features.to(device), target.to(device)\n",
        "\n",
        "    # Clear out gradients from previous training batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass; feed inputs to model & get outputs\n",
        "    outputs = model(features)\n",
        "    \n",
        "    # Calculate loss between model's predictions & actual target\n",
        "    loss = criterion(outputs, target)\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Back propagate loss throughout the neural network\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on the current gradient\n",
        "    optimizer.step()\n",
        "  \n",
        "  print('Training Loss: ', train_loss/len(train))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 5.25 µs\n",
            "\n",
            "Epoch 1/20\n",
            "------------\n",
            "Training Loss:  0.25109163392335176\n",
            "\n",
            "Epoch 2/20\n",
            "------------\n",
            "Training Loss:  0.4179583420356115\n",
            "\n",
            "Epoch 3/20\n",
            "------------\n",
            "Training Loss:  0.5607612513626615\n",
            "\n",
            "Epoch 4/20\n",
            "------------\n",
            "Training Loss:  0.6920022243633867\n",
            "\n",
            "Epoch 5/20\n",
            "------------\n",
            "Training Loss:  0.8206156237050891\n",
            "\n",
            "Epoch 6/20\n",
            "------------\n",
            "Training Loss:  0.9429274183387558\n",
            "\n",
            "Epoch 7/20\n",
            "------------\n",
            "Training Loss:  1.0646540749818088\n",
            "\n",
            "Epoch 8/20\n",
            "------------\n",
            "Training Loss:  1.1832359367360672\n",
            "\n",
            "Epoch 9/20\n",
            "------------\n",
            "Training Loss:  1.314117278593282\n",
            "\n",
            "Epoch 10/20\n",
            "------------\n",
            "Training Loss:  1.4241107643892368\n",
            "\n",
            "Epoch 11/20\n",
            "------------\n",
            "Training Loss:  1.5360542360382776\n",
            "\n",
            "Epoch 12/20\n",
            "------------\n",
            "Training Loss:  1.6522953339852393\n",
            "\n",
            "Epoch 13/20\n",
            "------------\n",
            "Training Loss:  1.7596822007869681\n",
            "\n",
            "Epoch 14/20\n",
            "------------\n",
            "Training Loss:  1.875486525769035\n",
            "\n",
            "Epoch 15/20\n",
            "------------\n",
            "Training Loss:  1.9977002050727606\n",
            "\n",
            "Epoch 16/20\n",
            "------------\n",
            "Training Loss:  2.1130054808532197\n",
            "\n",
            "Epoch 17/20\n",
            "------------\n",
            "Training Loss:  2.2184530152007937\n",
            "\n",
            "Epoch 18/20\n",
            "------------\n",
            "Training Loss:  2.3235018445178865\n",
            "\n",
            "Epoch 19/20\n",
            "------------\n",
            "Training Loss:  2.444144869285325\n",
            "\n",
            "Epoch 20/20\n",
            "------------\n",
            "Training Loss:  2.562131156834463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipLOg12auh3j",
        "outputId": "e7c2a9f0-d08f-4317-8163-17265913ee25"
      },
      "source": [
        "# Testing loop\n",
        "%time\n",
        "\n",
        "# Variables to track predictions & target\n",
        "preds, targets = [], []\n",
        "\n",
        "# Putting model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Disabling gradient calculation with no_grad(). Deactivates auto_grad engine \n",
        "# and reduces memory usage and speeds up computations but back propagation not possible.\n",
        "with torch.no_grad():\n",
        "  for features, target in test:\n",
        "\n",
        "    # Pushing data to the device\n",
        "    features = features.to(device)\n",
        "\n",
        "    # Perform forward pass, collect outputs\n",
        "    output = model(features)\n",
        "\n",
        "    # Deatch predictions from the graph and append to list\n",
        "    preds.append(output.detach().cpu().numpy())\n",
        "    targets.append(target.numpy())\n",
        "\n",
        "# Converting preds to a simple list from a list of arrays\n",
        "preds = [0 if x[0][0] < 0 else 1 for x in preds]\n",
        "y_test = [x for x in y_test]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsAgYAL8vkl_",
        "outputId": "25b17850-a6e9-41d5-a1d0-6d1d128cd015"
      },
      "source": [
        "# Calculating MAE between predictions & target\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pprint import pprint\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "report = classification_report(y_test, preds)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc, report))\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.97        60\n",
            "   macro avg       0.49      0.49      0.49        60\n",
            "weighted avg       0.97      0.97      0.97        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UAXG0R2Hzca"
      },
      "source": [
        "## **4) Keras Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjyN9VvH5uu",
        "outputId": "6e465787-1b89-4e18-f2a0-53ac7ba983a7"
      },
      "source": [
        "# Importing keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "regressor = Sequential()\n",
        "regressor.add(Dense(units = 100, activation = 'relu', input_dim = input_dim))\n",
        "regressor.add(Dense(units = 200, activation = 'relu'))\n",
        "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the model with adam optimizer\n",
        "regressor.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')\n",
        "\n",
        "# Training the model\n",
        "history = regressor.fit(X_train, y_train, batch_size = 16, epochs = 20, verbose = 0)\n",
        "\n",
        "# Evaluating on test set\n",
        "y_pred = regressor.predict_classes(X_test)\n",
        "\n",
        "# Printing metrics\n",
        "acc_k = accuracy_score(y_test, y_pred)\n",
        "report_k = classification_report(y_test, y_pred)\n",
        "\n",
        "print('Accuracy: {}\\n\\n{}'.format(acc_k, report_k))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3e5e53ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy: 0.9833333333333333\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        59\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98        60\n",
            "   macro avg       0.49      0.50      0.50        60\n",
            "weighted avg       0.97      0.98      0.98        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}